{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objectif : scraper planet grimpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importation des librairies\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exemple de page :\n",
    "url = 'https://planetgrimpe.com/falaise/moustarde/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "if response.ok:\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falaise Moustardé, guide d’escalade Laruns. Topos, accessibilité, photos et avis des grimpeurs sur Moustardé\n"
     ]
    }
   ],
   "source": [
    "if response.ok:\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    title = soup.find('title')\n",
    "    print(title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falaise Moustardé\n",
      "---\n",
      "France \n",
      "Aquitaine \n",
      "Pyrénées Atlantiques \n",
      "Laruns\n",
      "---\n",
      "10 - 30m\n",
      "25\n",
      "Printemps, Automne\n",
      "5b 6b\n",
      "Modérée | 20min\n",
      "Sud, Sud-Est\n",
      "10m\n",
      "30m\n",
      "20m\n",
      "Couenne\n",
      "42.825834\n",
      "-0.3985238\n"
     ]
    }
   ],
   "source": [
    "# les infos qui nous intéressent :\n",
    "\n",
    "if response.ok:\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    \n",
    "    spot = soup.find('div', {'id': 'single_top'}).find('h1')\n",
    "    print(spot.text)\n",
    "    \n",
    "    localisation = soup.find('div', {'id': 'single_top'}).findAll('li')\n",
    "    #for i in pays:\n",
    "    #    print(i.text)\n",
    "    \n",
    "    longueurLocalisation = len(localisation)\n",
    "    \n",
    "    if longueurLocalisation == 0:\n",
    "        pays = \" \"\n",
    "        region = \" \"\n",
    "        departement = \" \"\n",
    "        ville = \" \"\n",
    "        print('---')\n",
    "        print('aucune info')\n",
    "        print('---')\n",
    "    elif longueurLocalisation == 1:\n",
    "        pays = localisation[0].text\n",
    "        region = \" \"\n",
    "        departement = \" \"\n",
    "        ville = \" \"\n",
    "        print('---')\n",
    "        print(pays)\n",
    "        print('Pas de région')\n",
    "        print('Pas de département')\n",
    "        print('Pas de ville')\n",
    "        print('---')\n",
    "    elif longueurLocalisation == 2:\n",
    "        pays = localisation[0].text\n",
    "        region = \" \"\n",
    "        departement = \" \"\n",
    "        ville = localisation[1].text\n",
    "        print('---')\n",
    "        print(pays)\n",
    "        print('Pas de région')\n",
    "        print('Pas de département')\n",
    "        print(ville)\n",
    "        print('---')\n",
    "    elif longueurLocalisation == 3:\n",
    "        pays = localisation[0].text\n",
    "        region = localisation[1].text\n",
    "        departement = \" \"\n",
    "        ville = localisation[2].text\n",
    "        print('---')\n",
    "        print(pays)\n",
    "        print(region)\n",
    "        print('Pas de département')\n",
    "        print(ville)\n",
    "        print('---')\n",
    "    elif longueurLocalisation == 4:\n",
    "        pays = localisation[0].text\n",
    "        region = localisation[1].text\n",
    "        departement = localisation[2].text\n",
    "        ville = localisation[3].text\n",
    "        print('---')\n",
    "        print(pays)\n",
    "        print(region)\n",
    "        print(departement)\n",
    "        print(ville)\n",
    "        print('---')\n",
    "    \n",
    "    infosPrincipalesSpot = soup.find('div', {'id': 'single_top'}).find('div', {'class': 'single_top_infos'}).findAll('div', {'class': 'single_top_infosbloc'})\n",
    "    #for i in infosPrincipalesSpot:\n",
    "    #    print(i.text)\n",
    "    \n",
    "    longueurInfosPrincipales = len(infosPrincipalesSpot)\n",
    "    \n",
    "    if longueurInfosPrincipales == 5:\n",
    "        hauteur = infosPrincipalesSpot[0].text\n",
    "        print(hauteur[:-7])\n",
    "        lignes = infosPrincipalesSpot[1].text\n",
    "        print(lignes[:-6])\n",
    "        meilleuresSaisons = infosPrincipalesSpot[2].text\n",
    "        print(meilleuresSaisons[:-18])\n",
    "        cotations = infosPrincipalesSpot[3].text\n",
    "        print(cotations[:-9])\n",
    "        approche = infosPrincipalesSpot[4].text\n",
    "        print(approche[:-29])\n",
    "    elif longueurInfosPrincipales == 6:\n",
    "        hauteur = infosPrincipalesSpot[1].text\n",
    "        print(hauteur[:-7])\n",
    "        lignes = infosPrincipalesSpot[2].text\n",
    "        print(lignes[:-6])\n",
    "        meilleuresSaisons = infosPrincipalesSpot[3].text\n",
    "        print(meilleuresSaisons[:-18])\n",
    "        cotations = infosPrincipalesSpot[4].text\n",
    "        print(cotations[:-9])\n",
    "        approche = infosPrincipalesSpot[5].text\n",
    "        print(approche[:-29])\n",
    "    \n",
    "    infosSupp = soup.find('div', {'id': 'page_ctn'}).find('ul').findAll('li')     \n",
    "    orientation = infosSupp[1].text\n",
    "    print(orientation[22:])\n",
    "    hauteurMin = infosSupp[3].text\n",
    "    print(hauteurMin[16:])\n",
    "    hauteurMax = infosSupp[4].text\n",
    "    print(hauteurMax[16:])\n",
    "    hauteurMoyenne = infosSupp[5].text\n",
    "    print(hauteurMoyenne[16:])\n",
    "    discipline = infosSupp[6].text\n",
    "    print(discipline[16:])\n",
    "    \n",
    "    coordonnees = soup.find('div', {'class': 'map_legende'}).find('span')\n",
    "    coord = coordonnees.text\n",
    "    coordSplit = coord.split('-')\n",
    "    \n",
    "    longueurCoordSplit = len(coordSplit)\n",
    "    \n",
    "    ## longitudes et latitudes positives :\n",
    "    if longueurCoordSplit == 3:\n",
    "        coordSplit0 = coordSplit[0]\n",
    "        coordSplit1 = coordSplit[1]\n",
    "        latitude = coordSplit0[11:20]\n",
    "        longitude = coordSplit1[1:9]\n",
    "        #print(coordSplit0)\n",
    "        #print(coordSplit1)\n",
    "        print(latitude)\n",
    "        print(longitude)\n",
    "    ## longitudes négatives, latitudes positives :\n",
    "    elif longueurCoordSplit == 5:\n",
    "        coordSplit0 = coordSplit[0]\n",
    "        coordSplit2 = coordSplit[2]\n",
    "        latitude = coordSplit0[11:20]\n",
    "        longitude = \"-\"+coordSplit2[0:9]\n",
    "        #print(coordSplit0)\n",
    "        #print(coordSplit2)\n",
    "        print(latitude)\n",
    "        print(longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('spotsPlanetGrimp.csv', 'w') as outf:\n",
    "    outf.write('spot; pays; region; departement; ville; hauteur; nb_lignes; meileures_saisons; cotations; approche; orientation; hauteur_min; hauteur_max; hauteur_moyenne; type; latitude; longitude\\n')\n",
    "    response = requests.get(url)\n",
    "    if response.ok:\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "        \n",
    "        spot = soup.find('div', {'id': 'single_top'}).find('h1')\n",
    "    \n",
    "        localisation = soup.find('div', {'id': 'single_top'}).findAll('li')\n",
    "        \n",
    "        longueurLocalisation = len(localisation)\n",
    "    \n",
    "        if longueurLocalisation == 0:\n",
    "            pays = \" \"\n",
    "            region = \" \"\n",
    "            departement = \" \"\n",
    "            ville = \" \"\n",
    "        elif longueurLocalisation == 1:\n",
    "            pays = localisation[0].text\n",
    "            region = \" \"\n",
    "            departement = \" \"\n",
    "            ville = \" \"\n",
    "        elif longueurLocalisation == 2:\n",
    "            pays = localisation[0].text\n",
    "            region = \" \"\n",
    "            departement = \" \"\n",
    "            ville = localisation[1].text\n",
    "        elif longueurLocalisation == 3:\n",
    "            pays = localisation[0].text\n",
    "            region = localisation[1].text\n",
    "            departement = \" \"\n",
    "            ville = localisation[2].text\n",
    "        elif longueurLocalisation == 4:\n",
    "            pays = localisation[0].text\n",
    "            region = localisation[1].text\n",
    "            departement = localisation[2].text\n",
    "            ville = localisation[3].text\n",
    "    \n",
    "        infosPrincipalesSpot = soup.find('div', {'id': 'single_top'}).find('div', {'class': 'single_top_infos'}).findAll('div', {'class': 'single_top_infosbloc'})\n",
    "        \n",
    "        longueurInfosPrincipales = len(infosPrincipalesSpot)\n",
    "    \n",
    "        if longueurInfosPrincipales == 5:\n",
    "            hauteur = infosPrincipalesSpot[0].text\n",
    "            lignes = infosPrincipalesSpot[1].text\n",
    "            meilleuresSaisons = infosPrincipalesSpot[2].text\n",
    "            cotations = infosPrincipalesSpot[3].text\n",
    "            approche = infosPrincipalesSpot[4].text\n",
    "        elif longueurInfosPrincipales == 6:\n",
    "            hauteur = infosPrincipalesSpot[1].text\n",
    "            lignes = infosPrincipalesSpot[2].text\n",
    "            meilleuresSaisons = infosPrincipalesSpot[3].text\n",
    "            cotations = infosPrincipalesSpot[4].text\n",
    "            approche = infosPrincipalesSpot[5].text\n",
    "        \n",
    "        infosSupp = soup.find('div', {'id': 'page_ctn'}).find('ul').findAll('li')     \n",
    "        orientation = infosSupp[1].text\n",
    "        hauteurMin = infosSupp[3].text\n",
    "        hauteurMax = infosSupp[4].text\n",
    "        hauteurMoyenne = infosSupp[5].text\n",
    "        discipline = infosSupp[6].text\n",
    "        \n",
    "        coordonnees = soup.find('div', {'class': 'map_legende'}).find('span')\n",
    "        coord = coordonnees.text\n",
    "        coordSplit = coord.split('-')\n",
    "\n",
    "        longueurCoordSplit = len(coordSplit)\n",
    "\n",
    "        ## longitudes et latitudes positives :\n",
    "        if longueurCoordSplit == 3:\n",
    "            coordSplit0 = coordSplit[0]\n",
    "            coordSplit1 = coordSplit[1]\n",
    "            latitude = coordSplit0[11:20]\n",
    "            longitude = coordSplit1[1:9]\n",
    "\n",
    "        ## longitudes négatives, latitudes positives :\n",
    "        elif longueurCoordSplit == 5:\n",
    "            coordSplit0 = coordSplit[0]\n",
    "            coordSplit2 = coordSplit[2]\n",
    "            latitude = coordSplit0[11:20]\n",
    "            longitude = \"-\"+coordSplit2[0:9]\n",
    "        \n",
    "        outf.write(spot.text +'; '\n",
    "                   +pays+'; '\n",
    "                   +region+'; '\n",
    "                   +departement+'; '\n",
    "                   +ville+'; '\n",
    "                   +hauteur[:-7]+'; '\n",
    "                   +lignes[:-6]+'; '\n",
    "                   +meilleuresSaisons[:-18]+'; '\n",
    "                   +cotations[:-9]+'; '\n",
    "                   +approche[:-29]+'; '\n",
    "                   +orientation[22:]+'; '\n",
    "                   +hauteurMin[16:]+'; '\n",
    "                   +hauteurMax[16:]+'; '\n",
    "                   +hauteurMoyenne[16:]+'; '\n",
    "                   +discipline[16:]+'; '\n",
    "                   +latitude+'; '\n",
    "                   +longitude+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "### reste à choper toutes les pages maintenant"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
